[Data]
;bert_model = 'bert-base-chinese'
bert_model = 'D:/pythonProject/bert-base-chinese'
[Network]
n_embed = 100
n_char_embed = 50
n_feat_embed = 100
n_bert_layers = 4
embed_dropout = .33
n_lstm_hidden = 400
n_lstm_layers = 3
lstm_dropout = .33
n_mlp_span = 500
n_mlp_label = 100
n_mlp = 500
mlp_dropout = .33
n_bert_out = 800

[Optimizer]
;lr = 1e-3
lr = 1e-5
mu = .9
nu = .9
epsilon = 1e-7
clip = 5.0
lr_rate = 20
decay = .75
warmup = 0.1
decay_epochs = 45

[Run]
batch_size = 5000
;batch_size=10000
epochs = 15
patience = 10
;epochs = 10000
;patience = 50
min_freq = 2

